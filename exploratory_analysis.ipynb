{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Bagging import Custom_Bagging\n",
    "from Boosting import Custom_Boosting\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Normalization\n",
    "def min_max_normalize(column):\n",
    "    return (column - column.min()) / (column.max() - column.min())\n",
    "\n",
    "data_min_max = X_train.apply(min_max_normalize)\n",
    "\n",
    "print(\"Min-Max Normalized Data:\")\n",
    "print(data_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('your_data.csv')\n",
    "data = data.iloc[:, 1:]\n",
    "X = data.drop(columns=['smoking']) \n",
    "y = data['smoking']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['eyesight(left)', 'height(cm)', 'hemoglobin', 'HDL', 'serum creatinine', 'hearing(left)', 'waist(cm)', 'fasting blood sugar', 'eyesight(right)']\n",
    "for column in column_name:\n",
    "    if column in data.columns:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.histplot(data[column], kde=True)\n",
    "        plt.title(f'Distribution of {column}')\n",
    "        plt.xlabel(column)\n",
    "        plt.show()\n",
    "\n",
    "        # Boxplot\n",
    "        sns.boxplot(x=data[column], color='lightblue')\n",
    "        plt.title(f'Boxplot of {column}')\n",
    "        plt.show()\n",
    "\n",
    "# Descriptive statistics\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bivariate Analysis\")\n",
    "numerical_columns = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(data[numerical_columns].corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "sns.pairplot(data[numerical_columns])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA example for dimensionality reduction\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(X_train[numerical_columns])\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(scaled_data)\n",
    "\n",
    "# PCA results visualization\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.7, color='purple')\n",
    "plt.title('PCA of Features')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping unrelevant features \n",
    "X_train= X_train.drop(['eyesight(left)', 'eyesight(right)', 'hearing(left)', 'id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are missing values in each column\n",
    "missing_values = X_train.isnull().sum()\n",
    "print(\"Missing Values in Each Column:\")\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR method to detect outliers\n",
    "Q1 = X_train.quantile(0.25)\n",
    "Q3 = X_train.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identify outliers\n",
    "outliers = ((X_train < (Q1 - 1.5 * IQR)) | (X_train > (Q3 + 1.5 * IQR)))\n",
    "# Extract and print only the outlier values\n",
    "outlier_values = X_train[outliers]\n",
    "\n",
    "# Drop NaN rows to list only the outliers\n",
    "outlier_values_clean = outlier_values.dropna(how='all')\n",
    "print(\"Clean Outliers (Non-NaN rows):\")\n",
    "print(outlier_values_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_outliers(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return ((series < (Q1 - 1.5 * IQR)) | (series > (Q3 + 1.5 * IQR))).sum()\n",
    "\n",
    "# Count outliers for each column\n",
    "outliers_count = X_train.apply(count_outliers)\n",
    "print(\"Outliers Count per Column:\")\n",
    "print(outliers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Define a function to handle outliers in each column\n",
    "def winsorize(X_train, feature, lower_percentile=5, upper_percentile=95):\n",
    "\n",
    "    lower_bound = np.percentile(X_train[feature], lower_percentile)\n",
    "    upper_bound = np.percentile(X_train[feature], upper_percentile)\n",
    "    \n",
    "    # Cap the outliers\n",
    "    X_train[feature] = np.clip(data[feature], lower_bound, upper_bound)\n",
    "\n",
    "feautues = ['height(cm)', 'hemoglobin', 'HDL', 'serum creatinine', 'waist(cm)', 'fasting blood sugar']\n",
    "for feature in feautues:\n",
    "    winsorize(X_train, feature)\n",
    "\n",
    "# Display the dataset after Winsorization\n",
    "print(\"Dataset after Winsorization:\")\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_outliers(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return ((series < (Q1 - 1.5 * IQR)) | (series > (Q3 + 1.5 * IQR))).sum()\n",
    "\n",
    "# Count outliers for each column\n",
    "outliers_count = X_train.apply(count_outliers)\n",
    "print(\"Outliers Count per Column:\")\n",
    "print(outliers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Score Normalization\n",
    "def z_score_normalize(column):\n",
    "    return (column - column.mean()) / column.std()\n",
    "\n",
    "normailzed_data_z_score = X_train.apply(z_score_normalize)\n",
    "\n",
    "print(\"Z-Score Normalized Data:\")\n",
    "print(normailzed_data_z_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Normalization\n",
    "def min_max_normalize(column):\n",
    "    return (column - column.min()) / (column.max() - column.min())\n",
    "\n",
    "data_min_max = X_train.apply(min_max_normalize)\n",
    "\n",
    "print(\"Min-Max Normalized Data:\")\n",
    "print(data_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "\n",
    "X_new = SelectKBest(score_func=f_classif, k=5).fit_transform(data_min_max, y_train)\n",
    "\n",
    "print(\"Top 5 Features based on ANOVA F-test:\")\n",
    "print(X_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#five features selected by ANOVA F-test : height(cm), hemoglobin, HDL, serum creatinine, waist(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_model = Custom_Bagging(DecisionTreeClassifier, n=50)\n",
    "boosting_model = Custom_Boosting(DecisionTreeClassifier, n=50)\n",
    "bagging_model.fit(X_new, y_train)\n",
    "boosting_model.fit(X_new, y_train)\n",
    "bagging_predictions = bagging_model.predict(X_test)\n",
    "boosting_predictions = boosting_model.predict(X_test)\n",
    "bagging_accuracy = accuracy_score(y_test, bagging_predictions)\n",
    "boosting_accuracy = accuracy_score(y_test, boosting_predictions)\n",
    "print(f\"Bagging Model Accuracy: {bagging_accuracy:.4f}\")\n",
    "print(f\"Boosting Model Accuracy: {boosting_accuracy:.4f}\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
    "rf_classifier.fit(X_new, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
